{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://explosion.ai/blog/parsing-english-in-python#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conllu import parse, parse_tree\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu_file(filename):\n",
    "    with open(filename) as input_file:\n",
    "        text = input_file.read()\n",
    "        result = parse(text)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "train = read_conllu_file('../../../../UD_Ukrainian-IU/uk_iu-ud-train.conllu')\n",
    "test = read_conllu_file('../../../../UD_Ukrainian-IU/uk_iu-ud-dev.conllu')\n",
    "val = read_conllu_file('../../../../UD_Ukrainian-IU/uk_iu-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_to_sent(parsed_toks):\n",
    "    return ' '.join([t['form'] for t in parsed_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–£ –¥–æ–º—ñ —Ä–∏–º—Å—å–∫–æ–≥–æ –ø–∞—Ç—Ä–∏—Ü—ñ—è –†—É—Ñ—ñ–Ω–∞ –±—É–ª–∞ –ø—Ä–µ–≥–∞—Ä–Ω–∞ —Ñ—Ä–µ—Å–∫–∞ , –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –í–µ–Ω–µ—Ä–∏ —Ç–∞ –ê–¥–æ–Ω—ñ—Å–∞ .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_to_sent(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('id', 1),\n",
       "              ('form', '–£'),\n",
       "              ('lemma', '—É'),\n",
       "              ('upostag', 'ADP'),\n",
       "              ('xpostag', 'Spsl'),\n",
       "              ('feats', OrderedDict([('Case', 'Loc')])),\n",
       "              ('head', 2),\n",
       "              ('deprel', 'case'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0003')]))]),\n",
       " OrderedDict([('id', 2),\n",
       "              ('form', '–¥–æ–º—ñ'),\n",
       "              ('lemma', '–¥—ñ–º'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncmsln'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Inan'),\n",
       "                            ('Case', 'Loc'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 6),\n",
       "              ('deprel', 'obl'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0004')]))]),\n",
       " OrderedDict([('id', 3),\n",
       "              ('form', '—Ä–∏–º—Å—å–∫–æ–≥–æ'),\n",
       "              ('lemma', '—Ä–∏–º—Å—å–∫–∏–π'),\n",
       "              ('upostag', 'ADJ'),\n",
       "              ('xpostag', 'Ao-msgf'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 4),\n",
       "              ('deprel', 'amod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0005')]))]),\n",
       " OrderedDict([('id', 4),\n",
       "              ('form', '–ø–∞—Ç—Ä–∏—Ü—ñ—è'),\n",
       "              ('lemma', '–ø–∞—Ç—Ä–∏—Ü—ñ–π'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncmsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 2),\n",
       "              ('deprel', 'nmod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0006')]))]),\n",
       " OrderedDict([('id', 5),\n",
       "              ('form', '–†—É—Ñ—ñ–Ω–∞'),\n",
       "              ('lemma', '–†—É—Ñ—ñ–Ω'),\n",
       "              ('upostag', 'PROPN'),\n",
       "              ('xpostag', 'Npmsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('NameType', 'Giv'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 4),\n",
       "              ('deprel', 'flat:title'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0007')]))]),\n",
       " OrderedDict([('id', 6),\n",
       "              ('form', '–±—É–ª–∞'),\n",
       "              ('lemma', '–±—É—Ç–∏'),\n",
       "              ('upostag', 'VERB'),\n",
       "              ('xpostag', 'Vapis-sf'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Aspect', 'Imp'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('Mood', 'Ind'),\n",
       "                            ('Number', 'Sing'),\n",
       "                            ('Tense', 'Past'),\n",
       "                            ('VerbForm', 'Fin')])),\n",
       "              ('head', 0),\n",
       "              ('deprel', 'root'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0008')]))]),\n",
       " OrderedDict([('id', 7),\n",
       "              ('form', '–ø—Ä–µ–≥–∞—Ä–Ω–∞'),\n",
       "              ('lemma', '–ø—Ä–µ–≥–∞—Ä–Ω–∏–π'),\n",
       "              ('upostag', 'ADJ'),\n",
       "              ('xpostag', 'Ao-fsns'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Case', 'Nom'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 8),\n",
       "              ('deprel', 'amod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0009')]))]),\n",
       " OrderedDict([('id', 8),\n",
       "              ('form', '—Ñ—Ä–µ—Å–∫–∞'),\n",
       "              ('lemma', '—Ñ—Ä–µ—Å–∫–∞'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncfsnn'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Inan'),\n",
       "                            ('Case', 'Nom'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 6),\n",
       "              ('deprel', 'nsubj'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000a'), ('SpaceAfter', 'No')]))]),\n",
       " OrderedDict([('id', 9),\n",
       "              ('form', ','),\n",
       "              ('lemma', ','),\n",
       "              ('upostag', 'PUNCT'),\n",
       "              ('xpostag', 'U'),\n",
       "              ('feats', None),\n",
       "              ('head', 10),\n",
       "              ('deprel', 'punct'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000b')]))]),\n",
       " OrderedDict([('id', 10),\n",
       "              ('form', '–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è'),\n",
       "              ('lemma', '–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncnsnn'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Inan'),\n",
       "                            ('Case', 'Nom'),\n",
       "                            ('Gender', 'Neut'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 8),\n",
       "              ('deprel', 'appos'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000c')]))]),\n",
       " OrderedDict([('id', 11),\n",
       "              ('form', '–í–µ–Ω–µ—Ä–∏'),\n",
       "              ('lemma', '–í–µ–Ω–µ—Ä–∞'),\n",
       "              ('upostag', 'PROPN'),\n",
       "              ('xpostag', 'Npfsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('NameType', 'Giv'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 10),\n",
       "              ('deprel', 'nmod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000d')]))]),\n",
       " OrderedDict([('id', 12),\n",
       "              ('form', '—Ç–∞'),\n",
       "              ('lemma', '—Ç–∞'),\n",
       "              ('upostag', 'CCONJ'),\n",
       "              ('xpostag', 'Ccs'),\n",
       "              ('feats', None),\n",
       "              ('head', 13),\n",
       "              ('deprel', 'cc'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000e')]))]),\n",
       " OrderedDict([('id', 13),\n",
       "              ('form', '–ê–¥–æ–Ω—ñ—Å–∞'),\n",
       "              ('lemma', '–ê–¥–æ–Ω—ñ—Å'),\n",
       "              ('upostag', 'PROPN'),\n",
       "              ('xpostag', 'Npmsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('NameType', 'Giv'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 11),\n",
       "              ('deprel', 'conj'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000f'), ('SpaceAfter', 'No')]))]),\n",
       " OrderedDict([('id', 14),\n",
       "              ('form', '.'),\n",
       "              ('lemma', '.'),\n",
       "              ('upostag', 'PUNCT'),\n",
       "              ('xpostag', 'U'),\n",
       "              ('feats', None),\n",
       "              ('head', 6),\n",
       "              ('deprel', 'punct'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000g')]))])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def shift_by_1(array):\n",
    "    return array[1:]\n",
    "def head(tok):\n",
    "    return tok['head'] if 'head' in tok else 0\n",
    "\n",
    "def is_left_arc(tok1, tok2):\n",
    "    return head(tok1) == tok2['id']\n",
    "\n",
    "def is_right_arc(tok1, tok2):\n",
    "    return tok1['id'] == head(tok2)\n",
    "\n",
    "def has_parent(tok1, rels):\n",
    "    all_with_parent = [pair[0] for pair in rels]\n",
    "    return tok1['id'] in all_with_parent\n",
    "\n",
    "def head_is_in_stack(queue_el, stack_el):\n",
    "    return head(queue_el) < stack_el['id']\n",
    "\n",
    "def return_static_oracle_action(s0, q0, rel, *args):\n",
    "    if s0 is None:\n",
    "        action = 'SHIFT'\n",
    "    elif q0 is None:\n",
    "        action = 'REDUCE'\n",
    "    elif is_left_arc(s0, q0):\n",
    "        action = 'LEFT'\n",
    "    elif is_right_arc(s0, q0):\n",
    "        action = 'RIGHT'\n",
    "    elif has_parent(s0, rel) and head_is_in_stack(q0, s0):\n",
    "        action = 'REDUCE'\n",
    "    else:\n",
    "        action = 'SHIFT'\n",
    "    return action\n",
    "\n",
    "\n",
    "# rels = [(child,parent)]\n",
    "def unwrap_to_relations(tree, get_action, extra_attrs = {}):\n",
    "    stack = [ROOT]\n",
    "    all_toks = tree.copy()\n",
    "    queue = tree.copy()\n",
    "    rel = []\n",
    "    actions = []\n",
    "    while len(queue) or len(stack):\n",
    "        s0 = stack[-1] if len(stack) else None\n",
    "        q0 = queue[0] if len(queue) else None\n",
    "        action = get_action(s0, q0, rel, stack, queue, all_toks, extra_attrs)\n",
    "        actions.append(action)\n",
    "        if action == 'LEFT':\n",
    "            if s0 and q0:\n",
    "                ids = (s0['id'], q0['id'])\n",
    "                if not ids in rel:\n",
    "                    rel.append(ids)\n",
    "                stack.pop()\n",
    "        elif action == 'RIGHT':\n",
    "            if s0 and q0:\n",
    "                ids = (q0['id'], s0['id'])\n",
    "                if not ids in rel:\n",
    "                    rel.append(ids)\n",
    "                stack.append(q0)\n",
    "                queue = shift_by_1(queue)\n",
    "        elif action == 'REDUCE':\n",
    "            if len(stack):\n",
    "                stack.pop()\n",
    "        elif action == 'SHIFT':\n",
    "            if not q0 is None:\n",
    "                stack.append(q0)\n",
    "                queue = shift_by_1(queue)\n",
    "        else:\n",
    "            raise Exception('Invalid action', action)\n",
    "\n",
    "    if len(actions) != len(tree) * 2 + 1:\n",
    "        print('Warning: len of actions is not tree*2+1: {} vs {}'.format(len(actions), len(tree) * 2 + 1))\n",
    "    return rel, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 2),\n",
       "  (3, 4),\n",
       "  (4, 2),\n",
       "  (5, 4),\n",
       "  (2, 6),\n",
       "  (6, 0),\n",
       "  (7, 8),\n",
       "  (8, 6),\n",
       "  (9, 10),\n",
       "  (10, 8),\n",
       "  (11, 10),\n",
       "  (12, 13),\n",
       "  (13, 11),\n",
       "  (14, 6)],\n",
       " ['SHIFT',\n",
       "  'LEFT',\n",
       "  'SHIFT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'RIGHT',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'RIGHT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'RIGHT',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'REDUCE'])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = train[0]\n",
    "unwrap_to_relations(tree, return_static_oracle_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_gold_relations(tree):\n",
    "    return [(tok['id'], head(tok)) for tok in tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel, actions = unwrap_to_relations(tree, return_static_oracle_action)\n",
    "g_rel = unwrap_gold_relations(tree)\n",
    "set(rel) == set(g_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the spacy post:\n",
    "- The first three words of the buffer (n0, n1, n2)\n",
    "- The top three words of the stack (s0, s1, s2)\n",
    "- The two leftmost children of s0 (s0b1, s0b2);\n",
    "- The two rightmost children of s0 (s0f1, s0f2);\n",
    "- The two leftmost children of n0 (n0b1, n0b2)\n",
    "\n",
    "For these 12 tokens, we refer to the word-form, the part-of-speech tag, and the number of left and right children attached to the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children_count(tok, rels):\n",
    "    count = 0\n",
    "    for (child_id, parent_id) in rels:\n",
    "        if tok['id'] == parent_id:\n",
    "            count += 1\n",
    "    return count\n",
    "def get_parents_count(tok, rels):\n",
    "    count = 0\n",
    "    for (child_id, parent_id) in rels:\n",
    "        if tok['id'] == child_id:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def single_word_features(label, dict_vals, keys, rels):\n",
    "    res = {}\n",
    "    if dict_vals is None:\n",
    "        return {}\n",
    "    for key in keys:\n",
    "        if key == 'child_count':\n",
    "            res[label + '_c_count'] = get_children_count(dict_vals, rels)\n",
    "        elif key == 'parent_count':\n",
    "            res[label + '_p_count'] = get_parents_count(dict_vals, rels)\n",
    "        elif (type(dict_vals[key]) == OrderedDict):\n",
    "            for inner_key in dict_vals[key]:\n",
    "                res[label + '_' + key + '_' + inner_key] = dict_vals[key][inner_key]\n",
    "        else:\n",
    "            res[label + '_' + key] = dict_vals[key]\n",
    "    return res\n",
    "\n",
    "def to_features(stk, buf, rels, all_toks):\n",
    "    def get_by_id(id):\n",
    "        for tok in all_toks:\n",
    "            if tok['id'] == id:\n",
    "                return tok\n",
    "        return None\n",
    "\n",
    "    def get_child_1(tok):\n",
    "        if not tok:\n",
    "            return None\n",
    "        for (child_id, parent_id) in rels:\n",
    "            if tok['id'] == parent_id:\n",
    "                return get_by_id(child_id)\n",
    "        return None\n",
    "    def get_head_1(tok):\n",
    "        if not tok:\n",
    "            return None\n",
    "        for (child_id, parent_id) in rels:\n",
    "            if tok['id'] == child_id:\n",
    "                return get_by_id(parent_id)\n",
    "        return None\n",
    "\n",
    "    def get_n(col, n):\n",
    "        if col and 0 <= n < len(col):\n",
    "            return col[n]\n",
    "        else:\n",
    "            return None\n",
    "    res = {\n",
    "        **single_word_features('stk_0', get_n(stk, 0), ['form', 'upostag', 'child_count', 'parent_count'], rels),\n",
    "        **single_word_features('stk_1', get_n(stk, 1), ['form', 'upostag', 'child_count', 'parent_count'], rels),\n",
    "        **single_word_features('stk_2', get_n(stk, 2), ['form', 'upostag'], rels),\n",
    "        **single_word_features('ldep_stk_0', get_head_1(get_n(stk, 0)), ['form', 'upostag'], rels),\n",
    "        **single_word_features('rdep_stk_0', get_child_1(get_n(stk, 0)), ['form', 'upostag'], rels),\n",
    "        **single_word_features('buf_0', get_n(buf, 0), ['form', 'upostag'], rels),\n",
    "        **single_word_features('buf_1', get_n(buf, 1), ['form', 'upostag'], rels),\n",
    "        **single_word_features('buf_2', get_n(buf, 2), ['form', 'upostag'], rels),\n",
    "        **single_word_features('ldep_buf_0', get_head_1(get_n(buf, 0)), ['form', 'upostag'], rels),\n",
    "        **single_word_features('rdep_buf_0', get_child_1(get_n(buf, 0)), ['upostag'], rels)\n",
    "        # **single_word_features('buf_1', get_n(buf, 0), ['form', 'lemma', 'upostag', 'feats', 'deprel']),\n",
    "    }\n",
    "    if len(stk) and len(buf):\n",
    "        res[\"distance\"] = buf[0][\"id\"] - stk[-1][\"id\"]\n",
    "    return res\n",
    "\n",
    "def create_oracle_storing_data():\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    def oracle_extracting_data(s0, q0, rels, stk, buf, all_toks, extra_attrs = {}):\n",
    "        action = return_static_oracle_action(s0, q0, rels, stk, buf, all_toks)\n",
    "        X = to_features(stk, buf, rels, all_toks)\n",
    "        y = action\n",
    "        X.update(extra_attrs)        \n",
    "        Xs.append(X)\n",
    "        ys.append(y)\n",
    "        return action\n",
    "    return Xs, ys, oracle_extracting_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = len(train)\n",
    "train_X, train_y, extractor = create_oracle_storing_data()\n",
    "for (i, tree) in enumerate(train):\n",
    "    unwrap_to_relations(tree, extractor)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_len = len(test)\n",
    "test_X, test_y, extractor = create_oracle_storing_data()\n",
    "for (i, tree) in enumerate(test):\n",
    "    unwrap_to_relations(tree, extractor)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_len = len(val)\n",
    "val_X, val_y, extractor = create_oracle_storing_data()\n",
    "for (i, tree) in enumerate(val):\n",
    "    unwrap_to_relations(tree, extractor)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vectorizer = DictVectorizer()\n",
    "dict_vectorizer.fit(train_X + test_X + val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(sparse_matrix):\n",
    "    sparse_matrix.data = np.nan_to_num(sparse_matrix.data)\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_X = fill_nans(dict_vectorizer.transform(train_X))\n",
    "test_features_X = fill_nans(dict_vectorizer.transform(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LogisticRegression(random_state=42)\n",
    "predictor.fit(train_features_X, train_y)\n",
    "train_y_predicted = predictor.predict(train_features_X)\n",
    "test_y_predicted = predictor.predict(test_features_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.77      0.88      0.82     38446\n",
      "     REDUCE       0.90      0.81      0.85     41165\n",
      "      RIGHT       0.83      0.78      0.80     34669\n",
      "      SHIFT       0.92      0.93      0.93     40429\n",
      "\n",
      "avg / total       0.86      0.85      0.85    154709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y, train_y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       LEFT       0.65      0.87      0.74     38446\n",
    "     REDUCE       0.84      0.69      0.76     41165\n",
    "      RIGHT       0.73      0.59      0.65     34669\n",
    "      SHIFT       0.89      0.91      0.90     40429\n",
    "\n",
    "avg / total       0.78      0.77      0.77    154709\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.65      0.74      0.69      5127\n",
      "     REDUCE       0.87      0.66      0.75      5821\n",
      "      RIGHT       0.61      0.67      0.64      4972\n",
      "      SHIFT       0.83      0.86      0.84      5399\n",
      "\n",
      "avg / total       0.75      0.73      0.73     21319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, test_y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "     precision    recall  f1-score   support\n",
    "\n",
    "       LEFT       0.58      0.73      0.65      5127\n",
    "     REDUCE       0.85      0.61      0.71      5821\n",
    "      RIGHT       0.54      0.54      0.54      4972\n",
    "      SHIFT       0.83      0.87      0.85      5399\n",
    "\n",
    "avg / total       0.71      0.69      0.69     21319\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Wow, something is off here, as I get 10% worse average performance compared to results from @mariana-scorp. I even copied random_state for predictor, assuming that issue might be originating from there, but ~ same result. ü§î~~ Issue here was me adding sentence_i features which added noise to the data, removing it fixed this specific issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_moves(stack_len, queue_len):\n",
    "    moves = []\n",
    "    if queue_len > 0:\n",
    "        moves.append('SHIFT')\n",
    "    if stack_len > 0 and queue_len > 0:\n",
    "        moves.append('LEFT')\n",
    "        moves.append('RIGHT')\n",
    "    if stack_len > 0:\n",
    "        moves.append('REDUCE')\n",
    "    return moves\n",
    "def oracle_from_predictor(hasher, predictor):\n",
    "    def action_from_predictor(s0, q0, rels, stk, buf, all_toks, extra_attrs = {}):\n",
    "        possible_moves = get_valid_moves(len(stk), len(buf))\n",
    "        in_X = to_features(stk, buf, rels, all_toks)\n",
    "        in_X = fill_nans(hasher.transform(in_X))\n",
    "        all_possibilities = list(zip(predictor.classes_, predictor.predict_proba(in_X)[0]))\n",
    "        valid_possibilities = [pair for pair in all_possibilities if pair[0] in possible_moves]\n",
    "        max_prob = sorted(valid_possibilities, key=lambda pair: -pair[1])[0][0]\n",
    "        return max_prob\n",
    "    return action_from_predictor\n",
    "\n",
    "def get_uas(dataset, oracle):\n",
    "    total = 0\n",
    "    tp = 0\n",
    "    for sample in dataset:\n",
    "        rel_gold, _ = unwrap_to_relations(tree, return_static_oracle_action)\n",
    "        rel_ours, _ = unwrap_to_relations(tree, oracle)\n",
    "        total += len(sample)\n",
    "        tp += len(set(rel_gold) & set(rel_ours))\n",
    "    return tp/total , tp, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train. 0.5408532850408799 (40617 out of 75098 are correct)\n",
      "On test. 0.5007231703789413 (5193 out of 10371 are correct)\n"
     ]
    }
   ],
   "source": [
    "our_oracle = oracle_from_predictor(dict_vectorizer, predictor)\n",
    "ratio, tp, total = get_uas(train, our_oracle)\n",
    "print('On {}. {} ({} out of {} are correct)'.format('train', ratio, tp, total))\n",
    "ratio, tp, total = get_uas(test, our_oracle)\n",
    "print('On {}. {} ({} out of {} are correct)'.format('test', ratio, tp, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "On train. 0.5408532850408799 (40617 out of 75098 are correct)\n",
    "On test. 0.5007231703789413 (5193 out of 10371 are correct)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- ‚úÖfix issue with low metrics\n",
    "- ‚úÖadd new features (counts as improving the algo):\n",
    "- üö´possibly dyn oracle\n",
    "- ‚úÖrun on new sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new features\n",
    "- adding ldep/rdep for stack[0] / queue[0] bumped avg precision/recall by 0.01 across both train / test, but it made uas drop by ~0.18 (to 0.36 on train and 0.33 on test)\n",
    "      - adding children / parent count for stk_0/buf_0 slightly improved peformance of action predictor on train, almost didn't on test, yet uas didn't change at all\n",
    "      - redid features similar to what described in https://explosion.ai/blog/parsing-english-in-python#features keeping following:\n",
    "        1. 'stk_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        2. 'stk_1' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        3. 'stk_2' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        4. 'ldep_stk_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        5. 'rdep_stk_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        6. 'buf_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        7. 'buf_1' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        8. 'buf_2' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        9. 'ldep_buf_0' ‚Äì ['form', 'upostag', 'child_count', 'parent_count']\n",
    "      It gave following results for action classification on train\n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "           LEFT       0.82      0.89      0.85     38446\n",
    "         REDUCE       0.90      0.85      0.87     41165\n",
    "          RIGHT       0.84      0.80      0.82     34669\n",
    "          SHIFT       0.92      0.93      0.92     40429\n",
    "\n",
    "    avg / total       0.87      0.87      0.87    154709\n",
    "    \n",
    "    and on test  \n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "           LEFT       0.63      0.72      0.67      5127\n",
    "         REDUCE       0.84      0.68      0.75      5821\n",
    "          RIGHT       0.61      0.64      0.62      4972\n",
    "          SHIFT       0.81      0.85      0.83      5399\n",
    "\n",
    "    avg / total       0.73      0.72      0.72     21319  \n",
    "    \n",
    "    and still gave same result on uas for train/test\n",
    "    - trying to figure out whether I can leave some of the features away, removed some of the features and ended up with some endless loops which might need special handling / default fallback for actions. Updated the code to have predict probabilities and filter out invalid moves (and choosing the most probable valid move) - it didn't affect the score, but supposedly, must make it possible to fully evaluate on any corpora\n",
    "    - not sure, but might be that 0.5 is upper bond for this classificator / approach on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on new sentences\n",
    "\n",
    "In order to run on new sentence, I need \n",
    "1. form / upostag for each token in sentence\n",
    "2. head / id for each token in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from difflib import Differ\n",
    "from pprint import pprint\n",
    "# import tokenize_uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö —Ñ—ñ—á –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—é http://ufal.mff.cuni.cz/udpipe/users-manual ‚Äì —Å—Ö–æ–∂–µ –Ω–∞ –≥–∞—Ä–Ω–∏–π —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∞–ª–µ –ø—ñ–¥ –º–æ—é –û–° –¥–ª—è REST —Å–µ—Ä–≤—ñ—Å–∞ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –∫–æ–º–ø—ñ–ª—é–≤–∞—Ç–∏, —Ç–æ–º—É –±—É–¥—É –≤–∏–∫–ª–∏–∫–∞—Ç–∏ –π–æ–≥–æ —Å –∫–æ–º–∞–Ω–¥–Ω—Ä–æ–≥–æ —Ä—è–¥–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_tree(tree):\n",
    "    res = []\n",
    "    for node in tree:\n",
    "        head = node[\"head\"]\n",
    "        res.append(\"{} <-- {}\\n\".format(node[\"form\"],\n",
    "                                 tree[head - 1][\"form\"]\n",
    "                                 if head > 0 else \"root\"))\n",
    "    return res\n",
    "def get_head_id(tok, rels):\n",
    "    if not tok:\n",
    "        return None\n",
    "    for (child_id, parent_id) in rels:\n",
    "        if tok['id'] == child_id:\n",
    "            return parent_id\n",
    "    return None\n",
    "def trace_rels(tree, rels):\n",
    "    res = []\n",
    "    for node in tree:\n",
    "        head = get_head_id(node, rels)\n",
    "        if head is None:\n",
    "            res.append(\"{} <-- N/A\\n\".format(node[\"form\"]))\n",
    "            continue\n",
    "        res.append(\"{} <-- {}\\n\".format(node[\"form\"],\n",
    "                         tree[head - 1][\"form\"]\n",
    "                         if head > 0 else \"root\"))\n",
    "    return res\n",
    "def sentence_to_dicts(sent):\n",
    "    res = []\n",
    "    result = subprocess.getoutput(\"echo \\\"{}\\\" | /Users/sudodoki/Downloads/udpipe-1.2.0-bin/bin-osx/udpipe --tokenize --tag --parse /Users/sudodoki/Downloads/Universal\\ Dependencies\\ 2.0\\ Models\\ for\\ UDPipe\\ \\(2017-08-01\\)/udpipe-ud-2.0-170801/ukrainian-ud-2.0-170801.udpipe\".format(sent))\n",
    "    lines = result.split('\\n')[5:-1]\n",
    "    for line in lines:\n",
    "        id, form, lemma, upostag, xpostag, feats, head, deprel, _, _ = line.split('\\t')\n",
    "        tok_dict = OrderedDict([('id', int(id)), ('form', form), ('lemma', lemma),\n",
    "                                ('upostag', upostag), ('xpostag', xpostag), ('feats', feats),\n",
    "                               ('head', int(head)), ('deprel', deprel)])\n",
    "        res.append(tok_dict)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = Differ()\n",
    "def compare(sentence):\n",
    "    gold = sentence_to_dicts(sentence)\n",
    "    rel_gold, _ = unwrap_to_relations(gold, return_static_oracle_action)\n",
    "    gold_res = trace_tree(gold)\n",
    "    \n",
    "    rel_ours, _ = unwrap_to_relations(gold, our_oracle)\n",
    "    our_res = trace_rels(gold, rel_ours)\n",
    "    \n",
    "    total = len(gold)\n",
    "    tp = len(set(rel_gold) & set(rel_ours))\n",
    "    print(\"Got {} ({} out of {})\".format(tp / total, tp, total))\n",
    "    \n",
    "    result = list(diff.compare(gold_res, our_res))\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0.4864864864864865 (18 out of 37)\n",
      "['  –ü—Ä–∏–≥–∞–¥—É—é <-- root\\n',\n",
      " '- , <-- –∑–≥–æ–¥–æ–º\\n',\n",
      " '- —É–∂–µ <-- –∑–≥–æ–¥–æ–º\\n',\n",
      " '- –∑–≥–æ–¥–æ–º <-- –ü—Ä–∏–≥–∞–¥—É—é\\n',\n",
      " '? ^^^^^^\\n',\n",
      " '+ , <-- –ü—Ä–∏–≥–∞–¥—É—é\\n',\n",
      " '? ^\\n',\n",
      " '+ —É–∂–µ <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '+ –∑–≥–æ–¥–æ–º <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '  , <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '  –∫–æ–ª–∏ <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '  —è <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '- –≤—ñ–¥–±—É–≤–∞–≤ <-- –∑–≥–æ–¥–æ–º\\n',\n",
      " '?              ^ ^ ^^\\n',\n",
      " '+ –≤—ñ–¥–±—É–≤–∞–≤ <-- –ü—Ä–∏–≥–∞–¥—É—é\\n',\n",
      " '?              ^^^ ^ ^^\\n',\n",
      " '  —Å–≤—ñ–π <-- —Ç–µ—Ä–º—ñ–Ω\\n',\n",
      " '  —Ç–µ—Ä–º—ñ–Ω <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '  —É <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '- —Ç–∞–±–æ—Ä—ñ <-- –≤—ñ–¥–±—É–≤–∞–≤\\n',\n",
      " '- ‚Ññ <-- –æ–±–ª–∞—Å—Ç—ñ\\n',\n",
      " '- 36 <-- –æ–±–ª–∞—Å—Ç—ñ\\n',\n",
      " '- —É <-- –æ–±–ª–∞—Å—Ç—ñ\\n',\n",
      " '- –ö—É—á–∏–Ω–æ <-- –ü–µ—Ä–º—Å—å–∫–æ—ó\\n',\n",
      " '+ —Ç–∞–±–æ—Ä—ñ <-- —Ç–µ—Ä–º—ñ–Ω\\n',\n",
      " '+ ‚Ññ <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '+ 36 <-- ‚Ññ\\n',\n",
      " '+ —É <-- N/A\\n',\n",
      " '+ –ö—É—á–∏–Ω–æ <-- N/A\\n',\n",
      " '  –ü–µ—Ä–º—Å—å–∫–æ—ó <-- –æ–±–ª–∞—Å—Ç—ñ\\n',\n",
      " '- –æ–±–ª–∞—Å—Ç—ñ <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '+ –æ–±–ª–∞—Å—Ç—ñ <-- –ö—É—á–∏–Ω–æ\\n',\n",
      " '  , <-- –æ—Ç—Ä–∏–º–∞–≤\\n',\n",
      " '  —è <-- –æ—Ç—Ä–∏–º–∞–≤\\n',\n",
      " '- –æ—Ç—Ä–∏–º–∞–≤ <-- –æ–±–ª–∞—Å—Ç—ñ\\n',\n",
      " '?              ^^^^^\\n',\n",
      " '+ –æ—Ç—Ä–∏–º–∞–≤ <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '?             +++ ^\\n',\n",
      " '  –≤—ñ–¥ <-- –ú–∏—Ö–∞—Å—ñ\\n',\n",
      " '  –ú–∏—Ö–∞—Å—ñ <-- –æ—Ç—Ä–∏–º–∞–≤\\n',\n",
      " '- –ª–∏—Å—Ç—ñ–≤–∫—É <-- –ú–∏—Ö–∞—Å—ñ\\n',\n",
      " '?              ^^^ ^\\n',\n",
      " '+ –ª–∏—Å—Ç—ñ–≤–∫—É <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '?              ^ ^^^\\n',\n",
      " '- –∑ <-- –æ–ø–∏—Å–æ–º\\n',\n",
      " '?        ^^^ -\\n',\n",
      " '+ –∑ <-- —Ç–æ–≥–æ\\n',\n",
      " '?       + ^\\n',\n",
      " '  –∂–∞—Ä—Ç—ñ–≤–ª–∏–≤–∏–º <-- –æ–ø–∏—Å–æ–º\\n',\n",
      " '- –æ–ø–∏—Å–æ–º <-- –ª–∏—Å—Ç—ñ–≤–∫—É\\n',\n",
      " '- —Ç–æ–≥–æ <-- –æ–ø–∏—Å–æ–º\\n',\n",
      " '+ –æ–ø–∏—Å–æ–º <-- –∑\\n',\n",
      " '+ —Ç–æ–≥–æ <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '  , <-- –≥–æ—Ç—É—î—Ç—å—Å—è\\n',\n",
      " '- —è–∫ <-- –≥–æ—Ç—É—î—Ç—å—Å—è\\n',\n",
      " '+ —è–∫ <-- –ö–∏—ó–≤\\n',\n",
      " '  –ö–∏—ó–≤ <-- –≥–æ—Ç—É—î—Ç—å—Å—è\\n',\n",
      " '- –≥–æ—Ç—É—î—Ç—å—Å—è <-- —Ç–æ–≥–æ\\n',\n",
      " '?                 ^^\\n',\n",
      " '+ –≥–æ—Ç—É—î—Ç—å—Å—è <-- —Ç–∞–±–æ—Ä—ñ\\n',\n",
      " '?                ++ ^^\\n',\n",
      " '  –¥–æ <-- —Å–≤—è—Ç–∫—É–≤–∞–Ω–Ω—è\\n',\n",
      " '  —Å–≤—è—Ç–∫—É–≤–∞–Ω–Ω—è <-- –≥–æ—Ç—É—î—Ç—å—Å—è\\n',\n",
      " '  —Å–≤–æ–≥–æ <-- 1500-–ª—ñ—Ç—Ç—è\\n',\n",
      " '- 1500-–ª—ñ—Ç—Ç—è <-- –≥–æ—Ç—É—î—Ç—å—Å—è\\n',\n",
      " '- . <-- –æ–±–ª–∞—Å—Ç—ñ\\n',\n",
      " '+ 1500-–ª—ñ—Ç—Ç—è <-- —Å–≤—è—Ç–∫—É–≤–∞–Ω–Ω—è\\n',\n",
      " '+ . <-- –ü—Ä–∏–≥–∞–¥—É—é\\n']\n"
     ]
    }
   ],
   "source": [
    "compare(\"–ü—Ä–∏–≥–∞–¥—É—é, —É–∂–µ –∑–≥–æ–¥–æ–º, –∫–æ–ª–∏ —è –≤—ñ–¥–±—É–≤–∞–≤ —Å–≤—ñ–π —Ç–µ—Ä–º—ñ–Ω —É —Ç–∞–±–æ—Ä—ñ ‚Ññ 36 —É –ö—É—á–∏–Ω–æ –ü–µ—Ä–º—Å—å–∫–æ—ó –æ–±–ª–∞—Å—Ç—ñ, —è –æ—Ç—Ä–∏–º–∞–≤ –≤—ñ–¥ –ú–∏—Ö–∞—Å—ñ –ª–∏—Å—Ç—ñ–≤–∫—É –∑ –∂–∞—Ä—Ç—ñ–≤–ª–∏–≤–∏–º –æ–ø–∏—Å–æ–º —Ç–æ–≥–æ, —è–∫ –ö–∏—ó–≤ –≥–æ—Ç—É—î—Ç—å—Å—è –¥–æ —Å–≤—è—Ç–∫—É–≤–∞–Ω–Ω—è —Å–≤–æ–≥–æ 1500-–ª—ñ—Ç—Ç—è.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0.64 (16 out of 25)\n",
      "['- 6 <-- C\\n',\n",
      " '- C <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '? ^\\n',\n",
      " '+ 6 <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '? ^\\n',\n",
      " '+ C <-- 6\\n',\n",
      " '  –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è <-- root\\n',\n",
      " '  –Ω–∞ <-- –ø–ª–µ—á–µ\\n',\n",
      " '  –ø–ª–µ—á–µ <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '  , <-- –ø–µ—Ä–µ–∫–æ—á—É—é—á–∏—Å—å\\n',\n",
      " '  –ø–µ—Ä–µ–∫–æ—á—É—é—á–∏—Å—å <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '  , <-- –ø—Ä–æ–ª—ñ—Ç–∞—î\\n',\n",
      " '  –ø—Ä–æ–ª—ñ—Ç–∞—î <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '- –º–µ—Ç—Ä—ñ–≤ <-- –ø—Ä–æ–ª—ñ—Ç–∞—î\\n',\n",
      " '+ –º–µ—Ç—Ä—ñ–≤ <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '- –ø‚Äô—è—Ç–¥–µ—Å—è—Ç <-- –º–µ—Ç—Ä—ñ–≤\\n',\n",
      " '?               ^^^^^^\\n',\n",
      " '+ –ø‚Äô—è—Ç–¥–µ—Å—è—Ç <-- N/A\\n',\n",
      " '?               ^^^\\n',\n",
      " '  —ñ <-- –≤–∏—Ç—è–≥—É—î—Ç—å—Å—è\\n',\n",
      " '- –≤–∏—Ç—è–≥—É—î—Ç—å—Å—è <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n',\n",
      " '?                  ^^^ ------\\n',\n",
      " '+ –≤–∏—Ç—è–≥—É—î—Ç—å—Å—è <-- –ø‚Äô—è—Ç–¥–µ—Å—è—Ç\\n',\n",
      " '?                  ^^^^   +\\n',\n",
      " '  –Ω–∞ <-- —Å–Ω—ñ–≥—É\\n',\n",
      " '  —Å–Ω—ñ–≥—É <-- –≤–∏—Ç—è–≥—É—î—Ç—å—Å—è\\n',\n",
      " '- –∑–∞ <-- –∫—Ä–æ–∫—ñ–≤\\n',\n",
      " '+ –∑–∞ <-- N/A\\n',\n",
      " '  –∫—ñ–ª—å–∫–∞ <-- –∫—Ä–æ–∫—ñ–≤\\n',\n",
      " '- –∫—Ä–æ–∫—ñ–≤ <-- —Å–Ω—ñ–≥—É\\n',\n",
      " '?            ^^^^^\\n',\n",
      " '+ –∫—Ä–æ–∫—ñ–≤ <-- –∑–∞\\n',\n",
      " '?            ^^\\n',\n",
      " '- –≤—ñ–¥ <-- —É–ª–∞–º–∫–∞–º–∏\\n',\n",
      " '+ –≤—ñ–¥ <-- N/A\\n',\n",
      " '- –∑–∞–±—Ä–∏–∑–∫–∞–Ω–æ—ó <-- —É–ª–∞–º–∫–∞–º–∏\\n',\n",
      " '?                 ^^^^^^^^\\n',\n",
      " '+ –∑–∞–±—Ä–∏–∑–∫–∞–Ω–æ—ó <-- N/A\\n',\n",
      " '?                 ^^^\\n',\n",
      " '  –ø–∞–ª–∞—é—á–∏–º–∏ <-- —É–ª–∞–º–∫–∞–º–∏\\n',\n",
      " '- —É–ª–∞–º–∫–∞–º–∏ <-- –∫—Ä–æ–∫—ñ–≤\\n',\n",
      " '+ —É–ª–∞–º–∫–∞–º–∏ <-- –∑–∞–±—Ä–∏–∑–∫–∞–Ω–æ—ó\\n',\n",
      " '  –ø–æ—Å–∞–¥–∫–æ–≤–æ—ó <-- —Å–º—É–≥–∏\\n',\n",
      " '  —Å–º—É–≥–∏ <-- —É–ª–∞–º–∫–∞–º–∏\\n',\n",
      " '  . <-- –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è\\n']\n"
     ]
    }
   ],
   "source": [
    "compare(\"6C –ø—Ä–∏–∑–µ–º–ª—è—î—Ç—å—Å—è –Ω–∞ –ø–ª–µ—á–µ, –ø–µ—Ä–µ–∫–æ—á—É—é—á–∏—Å—å, –ø—Ä–æ–ª—ñ—Ç–∞—î –º–µ—Ç—Ä—ñ–≤ –ø‚Äô—è—Ç–¥–µ—Å—è—Ç —ñ –≤–∏—Ç—è–≥—É—î—Ç—å—Å—è –Ω–∞ —Å–Ω—ñ–≥—É –∑–∞ –∫—ñ–ª—å–∫–∞ –∫—Ä–æ–∫—ñ–≤ –≤—ñ–¥ –∑–∞–±—Ä–∏–∑–∫–∞–Ω–æ—ó –ø–∞–ª–∞—é—á–∏–º–∏ —É–ª–∞–º–∫–∞–º–∏ –ø–æ—Å–∞–¥–∫–æ–≤–æ—ó —Å–º—É–≥–∏.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0.5666666666666667 (17 out of 30)\n",
      "['  –î—ñ–≤—á–∏–Ω–∞ <-- —Å—Ç–æ—è–ª–∞\\n',\n",
      " '  —Å—Ç–æ—è–ª–∞ <-- root\\n',\n",
      " '  —Ç–∞–º <-- —Å—Ç–æ—è–ª–∞\\n',\n",
      " '- , <-- –¥–µ\\n',\n",
      " '- –¥–µ <-- —Ç–∞–º\\n',\n",
      " '- –π <-- –±—É–ª–∞\\n',\n",
      " '- –±—É–ª–∞ <-- –¥–µ\\n',\n",
      " '- , <-- –¥–µ\\n',\n",
      " '+ , <-- N/A\\n',\n",
      " '+ –¥–µ <-- N/A\\n',\n",
      " '+ –π <-- N/A\\n',\n",
      " '+ –±—É–ª–∞ <-- —Å—Ç–æ—è–ª–∞\\n',\n",
      " '+ , <-- N/A\\n',\n",
      " '  —ñ <-- –Ω–∞–º–∞–≥–∞–ª–∞—Å—è\\n',\n",
      " '  –Ω–∞–º–∞–≥–∞–ª–∞—Å—è <-- —Å—Ç–æ—è–ª–∞\\n',\n",
      " '- –ø—Ä–∏–≤–µ—Å—Ç–∏ <-- –Ω–∞–º–∞–≥–∞–ª–∞—Å—è\\n',\n",
      " '+ –ø—Ä–∏–≤–µ—Å—Ç–∏ <-- —Å—Ç–æ—è–ª–∞\\n',\n",
      " '  –¥–æ <-- –ª–∞–¥—É\\n',\n",
      " '  –ª–∞–¥—É <-- –ø—Ä–∏–≤–µ—Å—Ç–∏\\n',\n",
      " '  —Å–∫—É–π–æ–≤–¥–∂–µ–Ω–µ <-- –≤–æ–ª–æ—Å—Å—è\\n',\n",
      " '- –≤–æ–ª–æ—Å—Å—è <-- –ø—Ä–∏–≤–µ—Å—Ç–∏\\n',\n",
      " '- , <-- —Ä–æ–∑–ª—é—á–µ–Ω–∞\\n',\n",
      " '+ –≤–æ–ª–æ—Å—Å—è <-- –ª–∞–¥—É\\n',\n",
      " '+ , <-- —Ç–∏–º\\n',\n",
      " '  –≤–∫—Ä–∞–π <-- —Ä–æ–∑–ª—é—á–µ–Ω–∞\\n',\n",
      " '- —Ä–æ–∑–ª—é—á–µ–Ω–∞ <-- –≤–æ–ª–æ—Å—Å—è\\n',\n",
      " '?               ^^^^^^^\\n',\n",
      " '+ —Ä–æ–∑–ª—é—á–µ–Ω–∞ <-- ,\\n',\n",
      " '?               ^\\n',\n",
      " '- —Ç–∏–º <-- —Ä–æ–∑–ª—é—á–µ–Ω–∞\\n',\n",
      " '+ —Ç–∏–º <-- –ª–∞–¥—É\\n',\n",
      " '  , <-- –ø–æ–±–∞—á–∏–ª–∏\\n',\n",
      " '  —â–æ <-- –ø–æ–±–∞—á–∏–ª–∏\\n',\n",
      " '  —Ü–µ <-- –ø–æ–±–∞—á–∏–ª–∏\\n',\n",
      " '- –ø–æ–±–∞—á–∏–ª–∏ <-- —Ä–æ–∑–ª—é—á–µ–Ω–∞\\n',\n",
      " '?              --- ----\\n',\n",
      " '+ –ø–æ–±–∞—á–∏–ª–∏ <-- –ª–∞–¥—É\\n',\n",
      " '?                ++\\n',\n",
      " '- –≤–æ–¥—ñ—ó <-- –ø–æ–±–∞—á–∏–ª–∏\\n',\n",
      " '+ –≤–æ–¥—ñ—ó <-- –ª–∞–¥—É\\n',\n",
      " '  , <-- —á–µ–∫–∞–ª–∏\\n',\n",
      " '  —è–∫—ñ <-- —á–µ–∫–∞–ª–∏\\n',\n",
      " '- —á–µ–∫–∞–ª–∏ <-- –≤–æ–¥—ñ—ó\\n',\n",
      " '?            ^^ ^^\\n',\n",
      " '+ —á–µ–∫–∞–ª–∏ <-- –ª–∞–¥—É\\n',\n",
      " '?            ^^ ^\\n',\n",
      " '  –Ω–∞ <-- –ø–µ—Ä–µ—ó–∑–¥—ñ\\n',\n",
      " '  –ø–µ—Ä–µ—ó–∑–¥—ñ <-- —á–µ–∫–∞–ª–∏\\n',\n",
      " '  . <-- —Å—Ç–æ—è–ª–∞\\n']\n"
     ]
    }
   ],
   "source": [
    "compare(\"–î—ñ–≤—á–∏–Ω–∞ —Å—Ç–æ—è–ª–∞ —Ç–∞–º, –¥–µ –π –±—É–ª–∞, —ñ –Ω–∞–º–∞–≥–∞–ª–∞—Å—è –ø—Ä–∏–≤–µ—Å—Ç–∏ –¥–æ –ª–∞–¥—É —Å–∫—É–π–æ–≤–¥–∂–µ–Ω–µ –≤–æ–ª–æ—Å—Å—è, –≤–∫—Ä–∞–π —Ä–æ–∑–ª—é—á–µ–Ω–∞ —Ç–∏–º, —â–æ —Ü–µ –ø–æ–±–∞—á–∏–ª–∏ –≤–æ–¥—ñ—ó, —è–∫—ñ —á–µ–∫–∞–ª–∏ –Ω–∞ –ø–µ—Ä–µ—ó–∑–¥—ñ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ—è–∫—ñ –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –≤–∏–¥–Ω–æ —É –∑–≤'—è–∑–∫—É –∑ —Ä—ñ–∑–Ω–æ—é —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—é (–º–æ–∂–ª–∏–≤–∏–º —Ä–æ–∑–≤'—è–∑–∫–æ–º –±—É–ª–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è tokenize_uk —ñ –≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è tokenize —É udpipe). –ù–∞ –¥–∞–Ω–∏—Ö —Ä–µ—á–µ–Ω–Ω—è—Ö uas –≤–∞—Ä—ñ—é—î—Ç—å—Å—è 0.5-0.6, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
